{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Kernel Reductions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sections\n",
    "- [What are Reductions?](#What-are-Reductions?)\n",
    "- _Code:_ [Reduction with single_task](#Reduction-with-single_task)\n",
    "- [Group Reduction](#Group-Reduction)\n",
    "- _Code:_ [Reduction using work_group reduce](#Reduction-using-work_group-reduce)\n",
    "- [Reduction object in parallel_for](#Reduction-simplification-in-parallel_for)\n",
    "- _Code:_ [Reduction in parallel_for USM](#Reduction-in-parallel_for-USM)\n",
    "- _Code:_ [Reduction in parallel_for Buffers](#Reduction-in-parallel_for-Buffers)\n",
    "- _Code:_ [Multiple Reductions in one kernel](#Multiple-Reductions-in-one-kernel)\n",
    "- _Code:_ [Reduction with Custom Operator](#Reduction-with-Custom-Operator)\n",
    "- _Lab Exercise:_ [Kernel Reduction](#Lab-Exercise:-Kernel-Reduction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Understand how reductions can be performed with parallel kernels\n",
    "- Take advantages __reduce group function__ to do reduction at sub_group and work_group level\n",
    "- Use __reduction object__ to simplify reduction with parallel kernels\n",
    "- Use __multiple__ reductions in a single kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are Reductions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A __reduction produces a single value by combining multiple values__ in an unspecified order, using an operator that is both associative and commutative (e.g. addition). Only the final value resulting from a reduction is of interest to the programmer.\n",
    "\n",
    "A very common example is calculating __sum__ by adding a bunch of values.\n",
    "\n",
    "Parallelizing reductions can be tricky because of the nature of computation and accelerator hardware. Let's look at code examples showing how reduction can be performed on GPU using kernel invocation using __single_task__ and __parallel_for__:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduction with single_task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplest way to write a kernel function to compute sum for GPU is using a kernel invocation using __single_task__ and using a simple __for-loop__ to compute the sum of all values in the array. This way of reduction works but there is no parallelism in computation.\n",
    "\n",
    "```cpp\n",
    "  q.single_task([=](){\n",
    "    int sum = 0;\n",
    "    for(int i=0;i<N;i++){\n",
    "        sum += data[i];\n",
    "    }\n",
    "    data[0] = sum;\n",
    "  });\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SYCL code below demonstrates computing sum of array of values using `single_task` for kernel invocation.\n",
    "1. Inspect the code cell below and click run ▶ to save the code to file\n",
    "2. Next run ▶ the cell in the __Build and Run__ section below the code to compile and execute the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting lab/sum_single_task.cpp\n"
     ]
    }
   ],
   "source": [
    "%%writefile lab/sum_single_task.cpp\n",
    "//==============================================================\n",
    "// Copyright © Intel Corporation\n",
    "//\n",
    "// SPDX-License-Identifier: MIT\n",
    "// =============================================================\n",
    "#include <CL/sycl.hpp>\n",
    "using namespace sycl;\n",
    "\n",
    "static constexpr size_t N = 1024; // global size\n",
    "\n",
    "int main() {\n",
    "  //# setup sycl::queue with default device selector\n",
    "  queue q;\n",
    "  std::cout << \"Device : \" << q.get_device().get_info<info::device::name>() << \"\\n\";\n",
    "\n",
    "  //# initialize data array using usm\n",
    "  auto data = malloc_shared<int>(N, q);\n",
    "  for (int i = 0; i < N; i++) data[i] = i;\n",
    "\n",
    "  //# user single_task to add all numbers\n",
    "  q.single_task([=](){\n",
    "    int sum = 0;\n",
    "    for(int i=0;i<N;i++){\n",
    "        sum += data[i];\n",
    "    }\n",
    "    data[0] = sum;\n",
    "  }).wait();\n",
    "\n",
    "  std::cout << \"Sum = \" << data[0] << \"\\n\";\n",
    "  \n",
    "  free(data, q);\n",
    "  return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build and Run\n",
    "Select the cell below and click run ▶ to compile and execute the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job has been submitted to Intel(R) DevCloud and will execute soon.\n",
      "\n",
      "Job ID                    Name             User            Time Use S Queue\n",
      "------------------------- ---------------- --------------- -------- - -----\n",
      "2256147.v-qsvr-1           ...ub-singleuser u181188         00:00:36 R jupyterhub     \n",
      "2256226.v-qsvr-1           run_simple.sh    u181188         00:13:25 R batch          \n",
      "2256243.v-qsvr-1           ...r_creation.sh u181188                0 R batch          \n",
      "2256244.v-qsvr-1           ...ingle_task.sh u181188                0 Q batch          \n",
      "\n",
      "Waiting for Output ██████████████████████████████████████████████ Done⬇\n",
      "\n",
      "########################################################################\n",
      "#      Date:           Sat 18 Mar 2023 05:05:14 PM PDT\n",
      "#    Job ID:           2256244.v-qsvr-1.aidevcloud\n",
      "#      User:           u181188\n",
      "# Resources:           cput=75:00:00,neednodes=1:gpu:ppn=2,nodes=1:gpu:ppn=2,walltime=06:00:00\n",
      "########################################################################\n",
      "\n",
      "## u181188 is compiling DPCPP_Essentials Module8 -- DPCPP Reduction - 1 of 8 sum_single_task.cpp\n",
      "Device : Intel(R) UHD Graphics [0x9a60]\n",
      "Sum = 523776\n",
      "\n",
      "########################################################################\n",
      "# End of output for job 2256244.v-qsvr-1.aidevcloud\n",
      "# Date: Sat 18 Mar 2023 05:05:23 PM PDT\n",
      "########################################################################\n",
      "\n",
      "icpx: warning: use of 'dpcpp' is deprecated and will be removed in a future release. Use 'icpx -fsycl' [-Wdeprecated]\n",
      "Job Completed in 46 seconds.\n"
     ]
    }
   ],
   "source": [
    "! chmod 755 q; chmod 755 run_sum_single_task.sh; if [ -x \"$(command -v qsub)\" ]; then ./q run_sum_single_task.sh; else ./run_sum_single_task.sh; fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduction with parallel_for"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ND-Range kernel allows grouping executions that map to __compute units__ on hardware which allows for parallel execution of work-groups. As shows in the picture below, the entire range is divided into `work_group` which execute on a compute unit on the GPU hardware. Depending on number of compute units in the hardware, multiple work_groups can be executed to get parallelism. This allows to compute sum of each `work_group` and then it is further reduced to add all the work_group sums using a `single_task` kernel invocation. This gives better performance than the previous example which only uses `single_task` to do reduction.\n",
    "\n",
    "<img src=\"assets/hwmapping.png\" alt=\"hwmapping.png\" width=\"600\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `sycl::reduce_over_group()` function is group algorithm in SYCL which can also be used to perform certain common reduction operations in the kernel function for each `sub_group` or `work_group`. The reduce function can be used to **simplify reduction computation** with one line of code as shown below, instead of manually coding reduction with for-loop:\n",
    "\n",
    "\n",
    "```cpp\n",
    "      sum = sycl::reduce_over_group(group, data[i], sycl::plus<>());\n",
    "```\n",
    "\n",
    "The `sycl::reduce_over_group()` function takes three parameters: work-group/sub-group, work-item and operation to be performed on the group. There are various common parallel operations available like `sycl::plus<>()`, `sycl::maximum<>()` or `sycl::minimum<>()`\n",
    "\n",
    "Using this reduce function on a `sub_group` will optimize computation by leveraging sub_group shuffle operation to load values from register instead of making repeated access to global memory. The reduce function can also be used on a `work_group` which is also optimized implicitly by making use of sub_group functionality. \n",
    "\n",
    "The next section show how reduce function can be used on `work_group` to do reduction computation:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduction using work_group reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below uses work_group reduce function to add all items in a work_group and then the final computation is accomplished using single_task kernel invocation to add all work_group sums.\n",
    "\n",
    "The SYCL code below demonstrates work-group reduce: Inspect code, there are no modifications necessary:\n",
    "\n",
    "1. Inspect the code cell below and click run ▶ to save the code to file.\n",
    "\n",
    "2. Next run ▶ the cell in the __Build and Run__ section below the code to compile and execute the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting lab/sum_workgroup_reduce.cpp\n"
     ]
    }
   ],
   "source": [
    "%%writefile lab/sum_workgroup_reduce.cpp\n",
    "//==============================================================\n",
    "// Copyright © Intel Corporation\n",
    "//\n",
    "// SPDX-License-Identifier: MIT\n",
    "// =============================================================\n",
    "#include <CL/sycl.hpp>\n",
    "\n",
    "using namespace sycl;\n",
    "\n",
    "static constexpr size_t N = 1024; // global size\n",
    "static constexpr size_t B = 128; // work-group size\n",
    "\n",
    "int main() {\n",
    "  //# setup queue with in_order property\n",
    "  queue q(property::queue::in_order{});\n",
    "  std::cout << \"Device : \" << q.get_device().get_info<info::device::name>() << \"\\n\";\n",
    "\n",
    "  //# initialize data array using usm\n",
    "  auto data = malloc_shared<int>(N, q);\n",
    "  for (int i = 0; i < N; i++) data[i] = i;\n",
    "\n",
    "  //# use parallel_for to calculate sum for work_group using reduce\n",
    "  q.parallel_for(nd_range<1>(N, B), [=](nd_item<1> item){\n",
    "    auto wg = item.get_group();\n",
    "    auto i = item.get_global_id(0);\n",
    "\n",
    "    //# Adds all elements in work_group using work_group reduce\n",
    "    int sum_wg = reduce_over_group(wg, data[i], plus<>());\n",
    "\n",
    "    //# write work_group sum to first location for each work_group\n",
    "    if (item.get_local_id(0) == 0) data[i] = sum_wg;\n",
    "\n",
    "  });\n",
    "\n",
    "  q.single_task([=](){\n",
    "    int sum = 0;\n",
    "    for(int i=0;i<N;i+=B){\n",
    "        sum += data[i];\n",
    "    }\n",
    "    data[0] = sum;\n",
    "  }).wait();\n",
    "\n",
    "  std::cout << \"Sum = \" << data[0] << \"\\n\";\n",
    "\n",
    "  free(data, q);\n",
    "  return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build and Run\n",
    "Select the cell below and click run ▶ to compile and execute the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job has been submitted to Intel(R) DevCloud and will execute soon.\n",
      "\n",
      "Job ID                    Name             User            Time Use S Queue\n",
      "------------------------- ---------------- --------------- -------- - -----\n",
      "2256147.v-qsvr-1           ...ub-singleuser u181188         00:00:41 R jupyterhub     \n",
      "2256226.v-qsvr-1           run_simple.sh    u181188         00:14:10 R batch          \n",
      "2256251.v-qsvr-1           run_in_scan.sh   u181188                0 R batch          \n",
      "2256252.v-qsvr-1           ...oup_reduce.sh u181188                0 Q batch          \n",
      "\n",
      "Waiting for Output ████████████████████████████████████████████████████████████ Done⬇\n",
      "\n",
      "########################################################################\n",
      "#      Date:           Sat 18 Mar 2023 05:06:00 PM PDT\n",
      "#    Job ID:           2256252.v-qsvr-1.aidevcloud\n",
      "#      User:           u181188\n",
      "# Resources:           cput=75:00:00,neednodes=1:gpu:ppn=2,nodes=1:gpu:ppn=2,walltime=06:00:00\n",
      "########################################################################\n",
      "\n",
      "## u181188 is compiling DPCPP_Essentials Module8 -- DPCPP Reduction - 3 of 8 sum_workgroup_reduce.cpp\n",
      "Device : Intel(R) UHD Graphics [0x9a60]\n",
      "Sum = 523776\n",
      "\n",
      "########################################################################\n",
      "# End of output for job 2256252.v-qsvr-1.aidevcloud\n",
      "# Date: Sat 18 Mar 2023 05:06:10 PM PDT\n",
      "########################################################################\n",
      "\n",
      "icpx: warning: use of 'dpcpp' is deprecated and will be removed in a future release. Use 'icpx -fsycl' [-Wdeprecated]\n",
      "Job Completed in 60 seconds.\n"
     ]
    }
   ],
   "source": [
    "! chmod 755 q; chmod 755 run_sum_workgroup_reduce.sh; if [ -x \"$(command -v qsub)\" ]; then ./q run_sum_workgroup_reduce.sh; else ./run_sum_workgroup_reduce.sh; fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduction object in parallel_for"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous examples of reduction, the computation requires a two step approach to first perform reduction at group level and then perform reduction of output from each group. This section introduces to a new extension that will greatly simplify reduction computation.\n",
    "\n",
    "__SYCL introduces reduction to the ND-range version of parallel_for__, using syntax that is roughly aligned with OpenMP and C++ for_loop.\n",
    "\n",
    "It is common for parallel kernels to produce a single output resulting from some combination of all inputs (e.g. the sum). Writing efficient reductions is a complex task, depending on both device and runtime characteristics. Providing an abstraction for reductions in SYCL would greatly improve programmer productivity.\n",
    "\n",
    "`sycl::reduction` object in parallel_for encapsulates the reduction variable, an optional operator identity and the reduction operator as shown below:\n",
    "\n",
    "```cpp\n",
    "     q.parallel_for(nd_range<1>{N, B}, sycl::reduction(sum, sycl::plus<>()), [=](nd_item<1> it, auto& temp) {\n",
    "       int i = it.get_global_id(0);\n",
    "       temp.combine(data[i]);\n",
    "     });\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduction in parallel_for USM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below uses __sycl::reduction__ object in _parallel_for_ to compute the reduction with just one kernel using Unified Shared Memory(USM) for memory management.\n",
    "\n",
    "The SYCL code below demonstrates reduction in parallel_for with USM: Inspect code, there are no modifications necessary:\n",
    "\n",
    "1. Inspect the code cell below and click run ▶ to save the code to file.\n",
    "\n",
    "2. Next run ▶ the cell in the __Build and Run__ section below the code to compile and execute the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting lab/sum_reduction_usm.cpp\n"
     ]
    }
   ],
   "source": [
    "%%writefile lab/sum_reduction_usm.cpp\n",
    "//==============================================================\n",
    "// Copyright © Intel Corporation\n",
    "//\n",
    "// SPDX-License-Identifier: MIT\n",
    "// =============================================================\n",
    "#include <CL/sycl.hpp>\n",
    "\n",
    "using namespace sycl;\n",
    "\n",
    "static constexpr size_t N = 1024; // global size\n",
    "static constexpr size_t B = 128; // work-group size\n",
    "\n",
    "int main() {\n",
    "  //# setup queue with default selector\n",
    "  queue q;\n",
    "  std::cout << \"Device : \" << q.get_device().get_info<info::device::name>() << \"\\n\";\n",
    "\n",
    "  //# initialize data array using usm\n",
    "  auto data = malloc_shared<int>(N, q);\n",
    "  for (int i = 0; i < N; i++) data[i] = i;\n",
    "\n",
    "  //# implicit USM for writing sum value\n",
    "  int* sum = malloc_shared<int>(1, q);\n",
    "  *sum = 0;\n",
    "\n",
    "  //# nd-range kernel parallel_for with reduction parameter\n",
    "  q.parallel_for(nd_range<1>{N, B}, reduction(sum, plus<>()), [=](nd_item<1> it, auto& temp) {\n",
    "    auto i = it.get_global_id(0);\n",
    "    temp.combine(data[i]);\n",
    "  }).wait();\n",
    "\n",
    "  std::cout << \"Sum = \" << *sum << \"\\n\";\n",
    "\n",
    "  free(data, q);\n",
    "  free(sum, q);\n",
    "  return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build and Run\n",
    "Select the cell below and click run ▶ to compile and execute the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job has been submitted to Intel(R) DevCloud and will execute soon.\n",
      "\n",
      "Job ID                    Name             User            Time Use S Queue\n",
      "------------------------- ---------------- --------------- -------- - -----\n",
      "2256147.v-qsvr-1           ...ub-singleuser u181188         00:00:53 R jupyterhub     \n",
      "2256226.v-qsvr-1           run_simple.sh    u181188         00:15:41 R batch          \n",
      "2256257.v-qsvr-1           ...dpl_buffer.sh u181188                0 R batch          \n",
      "2256258.v-qsvr-1           run_ex_scan.sh   u181188                0 R batch          \n",
      "2256259.v-qsvr-1           ...group_info.sh u181188                0 Q batch          \n",
      "2256260.v-qsvr-1           ...uction_usm.sh u181188                0 Q batch          \n",
      "\n",
      "Waiting for Output ██████████████████████████████ Done⬇\n",
      "\n",
      "########################################################################\n",
      "#      Date:           Sat 18 Mar 2023 05:07:01 PM PDT\n",
      "#    Job ID:           2256260.v-qsvr-1.aidevcloud\n",
      "#      User:           u181188\n",
      "# Resources:           cput=75:00:00,neednodes=1:gpu:ppn=2,nodes=1:gpu:ppn=2,walltime=06:00:00\n",
      "########################################################################\n",
      "\n",
      "## u181188 is compiling DPCPP_Essentials Module8 -- DPCPP Reduction - 4 of 8 sum_reduction_usm.cpp\n",
      "Device : Intel(R) UHD Graphics [0x9a60]\n",
      "Sum = 523776\n",
      "\n",
      "########################################################################\n",
      "# End of output for job 2256260.v-qsvr-1.aidevcloud\n",
      "# Date: Sat 18 Mar 2023 05:07:11 PM PDT\n",
      "########################################################################\n",
      "\n",
      "icpx: warning: use of 'dpcpp' is deprecated and will be removed in a future release. Use 'icpx -fsycl' [-Wdeprecated]\n",
      "Job Completed in 30 seconds.\n"
     ]
    }
   ],
   "source": [
    "! chmod 755 q; chmod 755 run_sum_reduction_usm.sh; if [ -x \"$(command -v qsub)\" ]; then ./q run_sum_reduction_usm.sh; else ./run_sum_reduction_usm.sh; fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduction in parallel_for Buffers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below uses __sycl::reduction__ object in _parallel_for_ to compute the reduction with just one kernel using SYCL buffers and accessors for memory management.\n",
    "\n",
    "The SYCL code below demonstrates reduction in parallel_for with Buffers: Inspect code, there are no modifications necessary:\n",
    "\n",
    "1. Inspect the code cell below and click run ▶ to save the code to file.\n",
    "\n",
    "2. Next run ▶ the cell in the __Build and Run__ section below the code to compile and execute the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting lab/sum_reduction_buffers.cpp\n"
     ]
    }
   ],
   "source": [
    "%%writefile lab/sum_reduction_buffers.cpp\n",
    "//==============================================================\n",
    "// Copyright © Intel Corporation\n",
    "//\n",
    "// SPDX-License-Identifier: MIT\n",
    "// =============================================================\n",
    "#include <CL/sycl.hpp>\n",
    "\n",
    "using namespace sycl;\n",
    "\n",
    "static constexpr size_t N = 1024; // global size\n",
    "static constexpr size_t B = 128; // work-group size\n",
    "\n",
    "int main() {\n",
    "  queue q;\n",
    "  std::cout << \"Device : \" << q.get_device().get_info<info::device::name>() << \"\\n\";\n",
    "\n",
    "  std::vector<int> data(N);\n",
    "  for (int i = 0; i < N; i++) data[i] = i;\n",
    "  int sum = 0;\n",
    "  {\n",
    "    //# create buffers for data and sum\n",
    "    buffer buf_data(data);\n",
    "    buffer buf_sum(&sum, range(1));\n",
    "\n",
    "    q.submit([&](handler& h) {\n",
    "      //# create accessors for buffer\n",
    "      accessor acc_data(buf_data, h, read_only);\n",
    "\n",
    "      //# nd-range kernel parallel_for with reduction parameter\n",
    "      h.parallel_for(nd_range<1>{N, B}, reduction(buf_sum, h, plus<>()), [=](nd_item<1> it, auto& temp) {\n",
    "        auto i = it.get_global_id(0);\n",
    "        temp.combine(acc_data[i]);\n",
    "      });\n",
    "    });\n",
    "  }\n",
    "  std::cout << \"Sum = \" << sum << \"\\n\";\n",
    "\n",
    "  return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build and Run\n",
    "Select the cell below and click run ▶ to compile and execute the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job has been submitted to Intel(R) DevCloud and will execute soon.\n",
      "\n",
      "Job ID                    Name             User            Time Use S Queue\n",
      "------------------------- ---------------- --------------- -------- - -----\n",
      "2256147.v-qsvr-1           ...ub-singleuser u181188         00:01:00 R jupyterhub     \n",
      "2256226.v-qsvr-1           run_simple.sh    u181188         00:15:41 R batch          \n",
      "2256264.v-qsvr-1           ...sm_pointer.sh u181188                0 R batch          \n",
      "2256265.v-qsvr-1           ...ary_search.sh u181188                0 R batch          \n",
      "2256266.v-qsvr-1           ...on_buffers.sh u181188                0 Q batch          \n",
      "\n",
      "Waiting for Output █████████████████████████████ Done⬇\n",
      "\n",
      "########################################################################\n",
      "#      Date:           Sat 18 Mar 2023 05:07:32 PM PDT\n",
      "#    Job ID:           2256266.v-qsvr-1.aidevcloud\n",
      "#      User:           u181188\n",
      "# Resources:           cput=75:00:00,neednodes=1:gpu:ppn=2,nodes=1:gpu:ppn=2,walltime=06:00:00\n",
      "########################################################################\n",
      "\n",
      "## u181188 is compiling DPCPP_Essentials Module8 -- DPCPP Reduction - 5 of 8 sum_reduction_buffers.cpp\n",
      "Device : Intel(R) UHD Graphics [0x9a60]\n",
      "Sum = 523776\n",
      "\n",
      "########################################################################\n",
      "# End of output for job 2256266.v-qsvr-1.aidevcloud\n",
      "# Date: Sat 18 Mar 2023 05:07:42 PM PDT\n",
      "########################################################################\n",
      "\n",
      "icpx: warning: use of 'dpcpp' is deprecated and will be removed in a future release. Use 'icpx -fsycl' [-Wdeprecated]\n",
      "Job Completed in 29 seconds.\n"
     ]
    }
   ],
   "source": [
    "! chmod 755 q; chmod 755 run_sum_reduction_buffers.sh; if [ -x \"$(command -v qsub)\" ]; then ./q run_sum_reduction_buffers.sh; else ./run_sum_reduction_buffers.sh; fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Reductions in one kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below uses multiple __sycl::reduction__ objects in _parallel_for_ to compute the reductions with just one kernel using SYCL buffers and accessors for memory management.\n",
    "\n",
    "Multiple reductions are also supported with just one kernel, the code snippet below shows how to define a kernel using parallel_for with multiple reduction objects:\n",
    "\n",
    "```cpp\n",
    "h.parallel_for(nd_range<1>{N, B}, reduction1, reduction2, ..., [=](nd_item<1> it, auto& temp1, auto& temp2, ...) {\n",
    "  // kernel code\n",
    "});\n",
    "```\n",
    "\n",
    "The SYCL code below demonstrates multiple reduction in parallel_for with Buffers: Inspect code, there are no modifications necessary:\n",
    "\n",
    "1. Inspect the code cell below and click run ▶ to save the code to file.\n",
    "\n",
    "2. Next run ▶ the cell in the __Build and Run__ section below the code to compile and execute the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting lab/multiple_reductions_buffers.cpp\n"
     ]
    }
   ],
   "source": [
    "%%writefile lab/multiple_reductions_buffers.cpp\n",
    "//==============================================================\n",
    "// Copyright © Intel Corporation\n",
    "//\n",
    "// SPDX-License-Identifier: MIT\n",
    "// =============================================================\n",
    "#include <CL/sycl.hpp>\n",
    "\n",
    "using namespace sycl;\n",
    "\n",
    "static constexpr size_t N = 1024; // global size\n",
    "static constexpr size_t B = 128; // work-group size\n",
    "\n",
    "int main() {\n",
    "  queue q;\n",
    "  std::cout << \"Device : \" << q.get_device().get_info<info::device::name>() << \"\\n\";\n",
    "\n",
    "  //# initialize inputs and outputs\n",
    "  std::vector<int> data(N);\n",
    "  for (int i = 0; i < N; i++) data[i] = i;\n",
    "  int sum = 0, min = 0, max = 0;\n",
    "  {\n",
    "    //# create buffers\n",
    "    buffer buf_data(data);\n",
    "    buffer buf_sum(&sum, range(1));\n",
    "    buffer buf_min(&min, range(1));\n",
    "    buffer buf_max(&max, range(1));\n",
    "\n",
    "    q.submit([&](handler& h) {\n",
    "      //# create accessors for data and results\n",
    "      accessor acc_data(buf_data, h, read_only);\n",
    "        \n",
    "      //# define reduction objects for sum, min, max reduction\n",
    "      auto reduction_sum = reduction(buf_sum, h, plus<>());\n",
    "      auto reduction_min = reduction(buf_min, h, minimum<>());\n",
    "      auto reduction_max = reduction(buf_max, h, maximum<>());\n",
    "      \n",
    "      //# parallel_for with multiple reduction objects\n",
    "      h.parallel_for(nd_range<1>{N, B}, reduction_sum, reduction_min, reduction_max, [=](nd_item<1> it, auto& temp_sum, auto& temp_min, auto& temp_max) {\n",
    "        auto i = it.get_global_id();\n",
    "        temp_sum.combine(acc_data[i]);\n",
    "        temp_min.combine(acc_data[i]);\n",
    "        temp_max.combine(acc_data[i]);\n",
    "      });\n",
    "    });\n",
    "  }\n",
    " \n",
    "  //# print results\n",
    "  std::cout << \"Sum       = \" << sum << \"\\n\";\n",
    "  std::cout << \"Min       = \" << min << \"\\n\"; \n",
    "  std::cout << \"Max       = \" << max << \"\\n\";\n",
    "\n",
    "  return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build and Run\n",
    "Select the cell below and click run ▶ to compile and execute the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job has been submitted to Intel(R) DevCloud and will execute soon.\n",
      "\n",
      "Job ID                    Name             User            Time Use S Queue\n",
      "------------------------- ---------------- --------------- -------- - -----\n",
      "2256147.v-qsvr-1           ...ub-singleuser u181188         00:01:00 R jupyterhub     \n",
      "2256226.v-qsvr-1           run_simple.sh    u181188         00:16:26 R batch          \n",
      "2256272.v-qsvr-1           run_ex_scan.sh   u181188                0 R batch          \n",
      "2256273.v-qsvr-1           ...oup_reduce.sh u181188                0 R batch          \n",
      "2256274.v-qsvr-1           ...ns_buffers.sh u181188                0 Q batch          \n",
      "\n",
      "Waiting for Output ██████████████████████████████ Done⬇\n",
      "\n",
      "########################################################################\n",
      "#      Date:           Sat 18 Mar 2023 05:08:02 PM PDT\n",
      "#    Job ID:           2256274.v-qsvr-1.aidevcloud\n",
      "#      User:           u181188\n",
      "# Resources:           cput=75:00:00,neednodes=1:gpu:ppn=2,nodes=1:gpu:ppn=2,walltime=06:00:00\n",
      "########################################################################\n",
      "\n",
      "## u181188 is compiling DPCPP_Essentials Module8 -- DPCPP Reduction - 6 of 8 multiple_reductions_buffers.cpp\n",
      "Device : Intel(R) UHD Graphics [0x9a60]\n",
      "Sum       = 523776\n",
      "Min       = 0\n",
      "Max       = 1023\n",
      "\n",
      "########################################################################\n",
      "# End of output for job 2256274.v-qsvr-1.aidevcloud\n",
      "# Date: Sat 18 Mar 2023 05:08:12 PM PDT\n",
      "########################################################################\n",
      "\n",
      "icpx: warning: use of 'dpcpp' is deprecated and will be removed in a future release. Use 'icpx -fsycl' [-Wdeprecated]\n",
      "Job Completed in 30 seconds.\n"
     ]
    }
   ],
   "source": [
    "! chmod 755 q; chmod 755 run_multiple_reductions_buffers.sh; if [ -x \"$(command -v qsub)\" ]; then ./q run_multiple_reductions_buffers.sh; else ./run_multiple_reductions_buffers.sh; fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduction with Custom Operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below uses __sycl::reduction__ object in _parallel_for_ to compute the reduction object that uses a custom operator to find minimum value and index.\n",
    "\n",
    "The SYCL code below demonstrates reduction in parallel_for with custom user defined operator to perform reduction: Inspect code, there are no modifications necessary:\n",
    "\n",
    "1. Inspect the code cell below and click run ▶ to save the code to file.\n",
    "\n",
    "2. Next run ▶ the cell in the __Build and Run__ section below the code to compile and execute the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting lab/reduction_custom_operator.cpp\n"
     ]
    }
   ],
   "source": [
    "%%writefile lab/reduction_custom_operator.cpp\n",
    "//==============================================================\n",
    "// Copyright © Intel Corporation\n",
    "//\n",
    "// SPDX-License-Identifier: MIT\n",
    "// =============================================================\n",
    "#include <CL/sycl.hpp>\n",
    "#include <time.h>\n",
    "\n",
    "using namespace sycl;\n",
    "\n",
    "static constexpr size_t N = 256; // global size\n",
    "static constexpr size_t B = 64; // work-group size\n",
    "\n",
    "template <typename T, typename I>\n",
    "struct pair {\n",
    "  bool operator<(const pair& o) const {\n",
    "    return val <= o.val || (val == o.val && idx <= o.idx);\n",
    "  }\n",
    "  T val;\n",
    "  I idx;\n",
    "};\n",
    "\n",
    "int main() {\n",
    "  //# setup queue with default selector\n",
    "  queue q;\n",
    " \n",
    "  //# initialize input data and result using usm\n",
    "  auto result = malloc_shared<pair<int, int>>(1, q);\n",
    "  auto data = malloc_shared<int>(N, q);\n",
    "\n",
    "  //# initialize input data with random numbers\n",
    "  srand(time(0));\n",
    "  for (int i = 0; i < N; ++i) data[i] = rand() % 256;\n",
    "  std::cout << \"Input Data:\\n\";\n",
    "  for (int i = 0; i < N; i++) std::cout << data[i] << \" \"; std::cout << \"\\n\\n\";\n",
    "\n",
    "  //# custom operator for reduction to find minumum and index\n",
    "  pair<int, int> operator_identity = {std::numeric_limits<int>::max(), std::numeric_limits<int>::min()};\n",
    "  *result = operator_identity;\n",
    "  auto reduction_object = reduction(result, operator_identity, minimum<pair<int, int>>());\n",
    "\n",
    "  //# parallel_for with user defined reduction object\n",
    "  q.parallel_for(nd_range<1>{N, B}, reduction_object, [=](nd_item<1> item, auto& temp) {\n",
    "       int i = item.get_global_id(0);\n",
    "       temp.combine({data[i], i});\n",
    "  }).wait();\n",
    "\n",
    "  std::cout << \"Minimum value and index = \" << result->val << \" at \" << result->idx << \"\\n\";\n",
    "\n",
    "  free(result, q);\n",
    "  free(data, q);\n",
    "  return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build and Run\n",
    "Select the cell below and click run ▶ to compile and execute the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job has been submitted to Intel(R) DevCloud and will execute soon.\n",
      "\n",
      "Job ID                    Name             User            Time Use S Queue\n",
      "------------------------- ---------------- --------------- -------- - -----\n",
      "2256147.v-qsvr-1           ...ub-singleuser u181188         00:01:10 R jupyterhub     \n",
      "2256226.v-qsvr-1           run_simple.sh    u181188         00:17:11 R batch          \n",
      "2256278.v-qsvr-1           ...ary_search.sh u181188                0 R batch          \n",
      "2256279.v-qsvr-1           ...pper_bound.sh u181188                0 R batch          \n",
      "2256280.v-qsvr-1           ...roup_votes.sh u181188                0 Q batch          \n",
      "2256281.v-qsvr-1           ...m_operator.sh u181188                0 Q batch          \n",
      "\n",
      "Waiting for Output ██████████████████████████████ Done⬇\n",
      "\n",
      "########################################################################\n",
      "#      Date:           Sat 18 Mar 2023 05:08:32 PM PDT\n",
      "#    Job ID:           2256281.v-qsvr-1.aidevcloud\n",
      "#      User:           u181188\n",
      "# Resources:           cput=75:00:00,neednodes=1:gpu:ppn=2,nodes=1:gpu:ppn=2,walltime=06:00:00\n",
      "########################################################################\n",
      "\n",
      "## u181188 is compiling DPCPP_Essentials Module8 -- DPCPP Reduction - 7 of 8 reduction_custom_operator.cpp\n",
      "Input Data:\n",
      "125 251 45 207 45 7 167 246 0 123 210 95 205 17 33 200 227 162 159 151 223 112 57 58 171 208 110 160 80 205 234 205 200 23 156 245 30 67 236 31 190 190 126 139 207 159 84 179 65 243 74 33 99 131 91 15 83 202 175 163 151 153 112 95 177 12 84 207 79 64 238 13 255 108 152 206 12 236 129 77 223 203 110 67 78 202 82 161 148 1 68 43 155 180 138 76 192 222 27 15 31 10 28 30 118 181 236 130 161 110 208 129 57 62 196 136 8 22 41 156 23 110 199 178 34 81 254 227 48 26 242 79 36 15 109 154 196 89 29 101 199 237 230 1 43 170 137 52 192 178 208 216 32 152 138 67 233 137 38 25 163 24 104 199 39 213 97 235 47 126 81 246 107 55 247 151 226 128 203 162 51 155 122 83 51 5 150 29 142 188 54 49 213 159 248 252 116 89 232 163 216 57 154 67 112 145 218 82 18 165 245 69 65 111 152 116 116 47 145 2 235 200 51 192 103 43 189 219 133 165 127 93 222 25 160 78 170 123 161 188 32 150 1 97 5 154 214 122 201 103 124 180 47 176 117 150 \n",
      "\n",
      "Minimum value and index = 0 at 8\n",
      "\n",
      "########################################################################\n",
      "# End of output for job 2256281.v-qsvr-1.aidevcloud\n",
      "# Date: Sat 18 Mar 2023 05:08:42 PM PDT\n",
      "########################################################################\n",
      "\n",
      "icpx: warning: use of 'dpcpp' is deprecated and will be removed in a future release. Use 'icpx -fsycl' [-Wdeprecated]\n",
      "Job Completed in 30 seconds.\n"
     ]
    }
   ],
   "source": [
    "! chmod 755 q; chmod 755 run_reduction_custom_operator.sh; if [ -x \"$(command -v qsub)\" ]; then ./q run_reduction_custom_operator.sh; else ./run_reduction_custom_operator.sh; fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Lab Exercise: Kernel Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete the coding excercise below using Kernel Reduction concepts:\n",
    "- The code has an array `data` of size `N=1024` elements initialized\n",
    "- We will offload reduction kernel task to find the minimum and maximum values from the `data` array\n",
    "- Create reduction objects for finding minimum and maximum\n",
    "- Create reduction kernel using `parallel_for` with reduction objects for minimum and maximum.\n",
    "- On the host, compute mid-range, which is average of min and max values\n",
    "\n",
    "1. Edit the code cell below by following the steps and then click run ▶ to save the code to a file.\n",
    "2. Next run ▶ the cell in the __Build and Run__ section below the code to compile and execute the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting lab/reduction_lab.cpp\n"
     ]
    }
   ],
   "source": [
    "%%writefile lab/reduction_lab.cpp\n",
    "//==============================================================\n",
    "// Copyright © Intel Corporation\n",
    "//\n",
    "// SPDX-License-Identifier: MIT\n",
    "// =============================================================\n",
    "#include <CL/sycl.hpp>\n",
    "\n",
    "using namespace sycl;\n",
    "\n",
    "static constexpr size_t N = 1024; // global size\n",
    "static constexpr size_t B = 128; // work-group size\n",
    "\n",
    "int main() {\n",
    "  //# setup queue with default selector\n",
    "  queue q;\n",
    "  std::cout << \"Device : \" << q.get_device().get_info<info::device::name>() << \"\\n\";\n",
    "\n",
    "  //# initialize data array using usm\n",
    "  auto data = malloc_shared<int>(N, q);\n",
    "  for (int i = 0; i < N; i++) data[i] = i;\n",
    "\n",
    "  //# implicit USM for writing min and max value\n",
    "  int* min = malloc_shared<int>(1, q);\n",
    "  int* max = malloc_shared<int>(1, q);\n",
    "  *min = 0;\n",
    "  *max = 0;\n",
    "    \n",
    "  //# STEP 1 : Create reduction objects for computing min and max\n",
    "  \n",
    "  //# YOUR CODE GOES HERE\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  //# Reduction Kernel get min and max\n",
    "  q.submit([&](handler& h) {\n",
    "      \n",
    "    //# STEP 2 : add parallel_for with reduction objects for min and max\n",
    "    \n",
    "    //# YOUR CODE GOES HERE\n",
    "\n",
    "\n",
    "\n",
    "  }).wait();\n",
    "    \n",
    "  //# STEP 3 : Compute mid_range from min and max\n",
    "  int mid_range = 0;\n",
    "\n",
    "  //# YOUR CODE GOES HERE\n",
    "\n",
    "  std::cout << \"Mid-Range = \" << mid_range << \"\\n\";\n",
    "\n",
    "  free(data, q);\n",
    "  free(min, q);\n",
    "  free(max, q);\n",
    "  return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build and Run\n",
    "Select the cell below and click run ▶ to compile and execute the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job has been submitted to Intel(R) DevCloud and will execute soon.\n",
      "\n",
      "Job ID                    Name             User            Time Use S Queue\n",
      "------------------------- ---------------- --------------- -------- - -----\n",
      "2256147.v-qsvr-1           ...ub-singleuser u181188         00:01:24 R jupyterhub     \n",
      "2256226.v-qsvr-1           run_simple.sh    u181188         00:17:11 R batch          \n",
      "2256284.v-qsvr-1           ..._group_lab.sh u181188                0 R batch          \n",
      "2256285.v-qsvr-1           ...ower_bound.sh u181188                0 R batch          \n",
      "2256286.v-qsvr-1           ...uction_lab.sh u181188                0 Q batch          \n",
      "\n",
      "Waiting for Output ██████████████████████████████ Done⬇\n",
      "\n",
      "########################################################################\n",
      "#      Date:           Sat 18 Mar 2023 05:09:03 PM PDT\n",
      "#    Job ID:           2256286.v-qsvr-1.aidevcloud\n",
      "#      User:           u181188\n",
      "# Resources:           cput=75:00:00,neednodes=1:gpu:ppn=2,nodes=1:gpu:ppn=2,walltime=06:00:00\n",
      "########################################################################\n",
      "\n",
      "## u181188 is compiling DPCPP_Essentials Module8 -- DPCPP Reduction - 8 of 8 reduction_lab.cpp\n",
      "Device : Intel(R) UHD Graphics [0x9a60]\n",
      "Mid-Range = 0\n",
      "\n",
      "########################################################################\n",
      "# End of output for job 2256286.v-qsvr-1.aidevcloud\n",
      "# Date: Sat 18 Mar 2023 05:09:11 PM PDT\n",
      "########################################################################\n",
      "\n",
      "icpx: warning: use of 'dpcpp' is deprecated and will be removed in a future release. Use 'icpx -fsycl' [-Wdeprecated]\n",
      "Job Completed in 30 seconds.\n"
     ]
    }
   ],
   "source": [
    "! chmod 755 run_reduction_lab.sh; if [ -x \"$(command -v qsub)\" ]; then ./q run_reduction_lab.sh; else ./run_reduction_lab.sh; fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sycl::reduce_over_group` function for sub_group/work_group and `sycl::reduction` in parallel_for helps to optimize and simplify reduction computation in SYCL"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Intel® oneAPI 2023.0)",
   "language": "python",
   "name": "c009-intel_distribution_of_python_3_oneapi-beta05-python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "310.667px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
