{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edd0fbd4-17fa-472b-b8af-61cf67c8e668",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Local Memory and Atomics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a671ea02-7296-4d7c-8fc2-55424a991a98",
   "metadata": {},
   "source": [
    "##### Sections\n",
    "- [Local Memory Usage](#Local-Memory-Usage)\n",
    "- _Code:_ [Local Memory Type and Size](#Local-Memory-Type-and-Size)\n",
    "- [Local Accessors](#Local-Accessors)\n",
    "- [Group Barrier](#Group-Barrier)\n",
    "- _Code:_ [Matrix Multiplication without Local Memory](#Matrix-Multiplication-without-Local-Memory)\n",
    "- _Code:_ [Matrix Multiplication with Local Memory](#Matrix-Multiplication-with-Local-Memory)\n",
    "- [Atomic Operations](#Atomic-Operations)\n",
    "- _Code:_ [Atomic Operations with Buffers](#Atomic-Operations-with-Buffers)\n",
    "- _Code:_ [Atomic Operations with USM](#Atomic-Operations-with-USM)\n",
    "- _Lab Exercise:_ [Atomic Operation](#Lab-Exercise:-Atomic-Operation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60efc68-b77c-4e97-993d-5f5772e59b74",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "- Use local memory to avoid repeated global memory access\n",
    "- Understand the usage of group barriers to synchronize all work-items\n",
    "- Use atomic operation to perform reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f2a4fe-c794-43a2-8fa5-13fb9e2f0361",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Local Memory Usage\n",
    "\n",
    "Often work-items need to share data and communicate with each other. On one hand, all work-items in all work-groups can access global memory, so data sharing and communication can occur through global memory. However, due to its lower bandwidth and higher latency, sharing and communication through global memory is less efficient. On the other hand, work-items in a sub-group executing simultaneously in an execution unit (EU) thread can share data and communicate with each other very efficiently, but the number of work-items in a sub-group is usually small and the scope of data sharing and communication is very limited. \n",
    "\n",
    "Memory with higher bandwidth and lower latency accessible to a bigger scope of work-items is very desirable for data sharing communication among work-items. The shared local memory (SLM) in GPUs is designed for this purpose.\n",
    "\n",
    "To simplify kernel development and accelerate communication between work-items in a work-group, SYCL defines a special local memory space specifically for communication between work-items in a work-group.\n",
    "\n",
    "<img src=\"assets/localmem.png\">\n",
    "\n",
    "Each work-group may access variables in its own local memory space, but cannot access variables in another work-group’s local memory. When a work-group begins, the contents of its local memory are uninitialized, and local memory does not persist after a work-group finishes executing. Because of these properties, local memory may only be used for temporary storage while a work-group is executing.\n",
    "\n",
    "For some devices, such as for many CPU devices, local memory is a software abstraction and is implemented using the same memory subsystems as global memory. On these devices, using local memory is primarily a convenience mechanism for communication. Some compilers may use the memory space information for compiler local memory its own local memory optimizations, but otherwise using local memory for communication will not fundamentally perform better than communication via global memory on these devices.\n",
    "\n",
    "For other devices though, such as many GPU devices, there are dedicated resources for local memory, and on these devices, communicating via local memory will perform better than communicating via global memory.\n",
    "\n",
    "We can use the device query `info::device::local_mem_type` to determine whether an accelerator has dedicated resources for local memory or whether local memory is implemented as a software abstraction of global memory. \n",
    "\n",
    "We can use the device query `info::device::local_mem_size` to determine the size of local memory available for each work-group to access."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c2a89b-b945-489a-83b7-3c610cc24ce8",
   "metadata": {},
   "source": [
    "### Local Memory Type and Size\n",
    "\n",
    "The code below uses device query to determine the local memory size and type. Inspect code, there are no modifications necessary:\n",
    "\n",
    "1. Inspect the code cell below and click run ▶ to save the code to file.\n",
    "\n",
    "2. Next run ▶ the cell in the __Build and Run__ section below the code to compile and execute the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a159443-842d-484c-a7ad-6de93857e064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting lab/localmem_info.cpp\n"
     ]
    }
   ],
   "source": [
    "%%writefile lab/localmem_info.cpp\n",
    "//==============================================================\n",
    "// Copyright © Intel Corporation\n",
    "//\n",
    "// SPDX-License-Identifier: MIT\n",
    "// =============================================================\n",
    "#include <CL/sycl.hpp>\n",
    "\n",
    "using namespace cl::sycl;\n",
    "\n",
    "int main() {\n",
    "  queue q;\n",
    "\n",
    "  //# Print the device info\n",
    "  std::cout << \"device name   : \" << q.get_device().get_info<info::device::name>() << \"\\n\";\n",
    "  std::cout << \"local_mem_size: \" << q.get_device().get_info<info::device::local_mem_size>() << \"\\n\";\n",
    "\n",
    "  auto local_mem_type = q.get_device().get_info<info::device::local_mem_type>();\n",
    "  if(local_mem_type == info::local_mem_type::local) \n",
    "    std::cout << \"local_mem_type: info::local_mem_type::local\" << \"\\n\";\n",
    "  else if(local_mem_type == info::local_mem_type::global) \n",
    "    std::cout << \"local_mem_type: info::local_mem_type::global\" << \"\\n\";\n",
    "  else if(local_mem_type == info::local_mem_type::none) \n",
    "    std::cout << \"local_mem_type: info::local_mem_type::none\" << \"\\n\";\n",
    " \n",
    "  return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315bbd72-d910-43ce-8ef7-26967fbbee12",
   "metadata": {},
   "source": [
    "#### Build and Run\n",
    "Select the cell below and click run ▶ to compile and execute the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a447ad5-a382-4d49-b922-2433f8ee98dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job has been submitted to Intel(R) DevCloud and will execute soon.\n",
      "\n",
      "Job ID                    Name             User            Time Use S Queue\n",
      "------------------------- ---------------- --------------- -------- - -----\n",
      "2256147.v-qsvr-1           ...ub-singleuser u181188         00:00:41 R jupyterhub     \n",
      "2256226.v-qsvr-1           run_simple.sh    u181188         00:14:10 R batch          \n",
      "2256252.v-qsvr-1           ...oup_reduce.sh u181188                0 Q batch          \n",
      "2256253.v-qsvr-1           ...almem_info.sh u181188                0 Q batch          \n",
      "\n",
      "Waiting for Output ████████████████████████████████████████████████████████████ Done⬇\n",
      "\n",
      "########################################################################\n",
      "#      Date:           Sat 18 Mar 2023 05:06:01 PM PDT\n",
      "#    Job ID:           2256253.v-qsvr-1.aidevcloud\n",
      "#      User:           u181188\n",
      "# Resources:           cput=75:00:00,neednodes=1:gpu:ppn=2,nodes=1:gpu:ppn=2,walltime=06:00:00\n",
      "########################################################################\n",
      "\n",
      "## u181188 is compiling DPCPP_Essentials Module12 -- DPCPP Atomics Local Memory - 3 of 5 localmem_info.cpp\n",
      "device name   : Intel(R) UHD Graphics [0x9a60]\n",
      "local_mem_size: 65536\n",
      "local_mem_type: info::local_mem_type::local\n",
      "\n",
      "########################################################################\n",
      "# End of output for job 2256253.v-qsvr-1.aidevcloud\n",
      "# Date: Sat 18 Mar 2023 05:06:10 PM PDT\n",
      "########################################################################\n",
      "\n",
      "icpx: warning: use of 'dpcpp' is deprecated and will be removed in a future release. Use 'icpx -fsycl' [-Wdeprecated]\n",
      "Job Completed in 60 seconds.\n"
     ]
    }
   ],
   "source": [
    "! chmod 755 q; chmod 755 run_localmem_info.sh; if [ -x \"$(command -v qsub)\" ]; then ./q run_localmem_info.sh; else ./run_localmem_info.sh; fi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616663ca-ed92-44ac-a332-12b2596519ea",
   "metadata": {},
   "source": [
    "### Local Accessors\n",
    "\n",
    "A Local Accessor is used to declare local memory for use in an ND-range kernel. Like other accessor objects, a local accessor is constructed within a command group handler.\n",
    "\n",
    "A local accessor is created by specifying a type and a range describing the number of elements of that type. Like other accessors, local accessors may be one-dimensional, two-dimensional, or three dimensional.\n",
    "\n",
    "Below is an example of defining local accessor `localmem` using property `sycl::access::target::local` with type _int_ and _one-dimension_ \n",
    "\n",
    "```cpp\n",
    "accessor<int, 1, access::mode::read_write, access::target::local> localmem(N, h);\n",
    "```\n",
    "\n",
    "The local accessor from one work-group can be accessed by all work-items within the work-group. Each work-group can have its own local accessor, work-item from another work-group cannot access this local accessor.\n",
    "\n",
    "### Group Barrier\n",
    "\n",
    "When local accessor data is shared, work-group barriers are often required for work-item synchronization.\n",
    "\n",
    "The `group_barrier` function synchronizes how each work-item views the state of memory. This type of synchronization operation is known as enforcing memory consistency or fencing memory. It ensures that the results of memory operations performed before the barrier are visible to other work-items after the\n",
    "barrier.\n",
    "\n",
    "A `group_barrier` is usually required right after a local accessor is modified by a work-item so that it is synchronized for all work-items before the local accessor can be accessed.\n",
    "\n",
    "Below is an example of how a `group_barrier` function is defined to synchronize across all work-items within the work-group:\n",
    "\n",
    "```cpp\n",
    "group_barrier(item.get_group());\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7ca6e1-b25d-441b-adbf-2314568f456f",
   "metadata": {},
   "source": [
    "## Local Memory Usage Example\n",
    "\n",
    "When a computation requires repeated access to global memory data, using a local memory to load data from global memory and then accessing subsequent repeated access from local memory can be more performant.\n",
    "\n",
    "One such example is matrix multiplication, multiplying two 8x8 matrices requires each of 8 rows to multiply with 8 columns, every row and column is accessed 8 times from global memory. \n",
    "\n",
    "<img src=\"assets/naive.PNG\">\n",
    "\n",
    "Using local memory for matrix multiplication can be more performant. Let's look at matrix multiplication without using local memory and using local memory to understand usage of `local accessor` and `group_barrier` concepts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea43b38e-2c4c-4a24-afe7-617d0cf1a1ae",
   "metadata": {},
   "source": [
    "### Matrix Multiplication without Local Memory\n",
    "\n",
    "The code below demonstrates basic matrix multiplication example. Inspect code, there are no modifications necessary:\n",
    "\n",
    "1. Inspect the code cell below and click run ▶ to save the code to file.\n",
    "\n",
    "2. Next run ▶ the cell in the __Build and Run__ section below the code to compile and execute the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be897d90-2d92-464b-be20-26bdf6cde6a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting lab/matrixmul_16x16.cpp\n"
     ]
    }
   ],
   "source": [
    "%%writefile lab/matrixmul_16x16.cpp\n",
    "//==============================================================\n",
    "// Copyright © Intel Corporation\n",
    "//\n",
    "// SPDX-License-Identifier: MIT\n",
    "// =============================================================\n",
    "\n",
    "\n",
    "#include <CL/sycl.hpp>\n",
    "#include <iomanip>\n",
    "\n",
    "using namespace sycl;\n",
    "\n",
    "int main() {\n",
    "    \n",
    "    size_t N = 16;\n",
    "    std::cout << \"MATRIX_SIZE    : \" << N << \"x\" << N << std::endl;\n",
    "\n",
    "    //# Define vectors for matrices\n",
    "    std::vector<float> matrix_a(N*N);\n",
    "    std::vector<float> matrix_b(N*N);\n",
    "    std::vector<float> matrix_c(N*N);\n",
    "    std::vector<float> matrix_d(N*N);\n",
    "    \n",
    "    //# Initialize matrices with values\n",
    "    float v1 = 2.f;\n",
    "    float v2 = 3.f;\n",
    "    for (int i=0; i<N; i++)\n",
    "        for (int j=0; j<N; j++){\n",
    "            matrix_a[i*N+j] = v1++;\n",
    "            matrix_b[i*N+j] = v2++;\n",
    "            matrix_c[i*N+j] = 0.f;\n",
    "            matrix_d[i*N+j] = 0.f;\n",
    "    }\n",
    "    \n",
    "    //# Define queue with default device for offloading computation\n",
    "    queue q;\n",
    "    std::cout << \"Offload Device : \" << q.get_device().get_info<info::device::name>() << std::endl;\n",
    "    \n",
    "    //# Create buffers for matrices\n",
    "    buffer a(matrix_a);\n",
    "    buffer b(matrix_b);\n",
    "    buffer c(matrix_c);\n",
    "\n",
    "    //# Submit command groups to execute on device\n",
    "    q.submit([&](handler &h){\n",
    "        //# Create accessors to copy buffers to the device\n",
    "        accessor A(a, h, read_only);\n",
    "        accessor B(b, h, read_only);\n",
    "        accessor C(c, h, write_only);\n",
    "\n",
    "        //# Define size for ND-range and work-group size\n",
    "        range<2> global_size(N,N);\n",
    "        range<2> work_group_size(N,N);\n",
    "\n",
    "        //# Parallel Compute Matrix Multiplication\n",
    "        h.parallel_for(nd_range<2>{global_size, work_group_size}, [=](nd_item<2> item){\n",
    "            const int i = item.get_global_id(0);\n",
    "            const int j = item.get_global_id(1);\n",
    "\n",
    "            //# matrix multiplication computation from local memory\n",
    "            float temp = 0.f;\n",
    "            for (int k = 0; k < N; k++) {\n",
    "                temp += A[i*N+k] * B[k*N+j];\n",
    "            }\n",
    "            C[i*N+j] = temp;\n",
    "        });\n",
    "    });\n",
    "    host_accessor ha(c, read_only);\n",
    "    \n",
    "    //# Print Output and Verification\n",
    "    auto FAIL = 0;\n",
    "    for (int i=0; i<N; i++){\n",
    "        for (int j=0; j<N; j++){\n",
    "            for(int k=0; k<N; k++){\n",
    "                matrix_d[i*N+j] += matrix_a[i*N+k] * matrix_b[k*N+j];\n",
    "            }\n",
    "            if(matrix_d[i*N+j] != matrix_c[i*N+j]) FAIL = 1;\n",
    "            std::cout << std::setw(6) << matrix_c[i*N+j] << \" \";\n",
    "        }\n",
    "        std::cout << \"\\n\";\n",
    "    }\n",
    "    if(FAIL == 1) std::cout << \"FAIL\\n\"; else std::cout << \"PASS\\n\";\n",
    "\n",
    "    return 0;\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d6d041-c1d5-4039-a673-80c46a086a62",
   "metadata": {},
   "source": [
    "#### Build and Run\n",
    "Select the cell below and click run ▶ to compile and execute the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b2de30c-7b28-4f69-8c5d-7afd68347159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job has been submitted to Intel(R) DevCloud and will execute soon.\n",
      "\n",
      "Job ID                    Name             User            Time Use S Queue\n",
      "------------------------- ---------------- --------------- -------- - -----\n",
      "2256147.v-qsvr-1           ...ub-singleuser u181188         00:00:53 R jupyterhub     \n",
      "2256226.v-qsvr-1           run_simple.sh    u181188         00:15:41 R batch          \n",
      "2256257.v-qsvr-1           ...dpl_buffer.sh u181188                0 R batch          \n",
      "2256258.v-qsvr-1           run_ex_scan.sh   u181188                0 R batch          \n",
      "2256259.v-qsvr-1           ...group_info.sh u181188                0 R batch          \n",
      "2256260.v-qsvr-1           ...uction_usm.sh u181188                0 Q batch          \n",
      "2256261.v-qsvr-1           ...xmul_16x16.sh u181188                0 Q batch          \n",
      "\n",
      "Waiting for Output ██████████████████████████████ Done⬇\n",
      "\n",
      "########################################################################\n",
      "#      Date:           Sat 18 Mar 2023 05:07:03 PM PDT\n",
      "#    Job ID:           2256261.v-qsvr-1.aidevcloud\n",
      "#      User:           u181188\n",
      "# Resources:           cput=75:00:00,neednodes=1:gpu:ppn=2,nodes=1:gpu:ppn=2,walltime=06:00:00\n",
      "########################################################################\n",
      "\n",
      "## u181188 is compiling DPCPP_Essentials Module12 -- DPCPP Atomics Local Memory - 4 of 5 matrixmul_16x16_localmem.cpp\n",
      "MATRIX_SIZE    : 16x16\n",
      "Offload Device : Intel(R) UHD Graphics [0x9a60]\n",
      " 24136  24288  24440  24592  24744  24896  25048  25200  25352  25504  25656  25808  25960  26112  26264  26416 \n",
      " 55624  56032  56440  56848  57256  57664  58072  58480  58888  59296  59704  60112  60520  60928  61336  61744 \n",
      " 87112  87776  88440  89104  89768  90432  91096  91760  92424  93088  93752  94416  95080  95744  96408  97072 \n",
      "118600 119520 120440 121360 122280 123200 124120 125040 125960 126880 127800 128720 129640 130560 131480 132400 \n",
      "150088 151264 152440 153616 154792 155968 157144 158320 159496 160672 161848 163024 164200 165376 166552 167728 \n",
      "181576 183008 184440 185872 187304 188736 190168 191600 193032 194464 195896 197328 198760 200192 201624 203056 \n",
      "213064 214752 216440 218128 219816 221504 223192 224880 226568 228256 229944 231632 233320 235008 236696 238384 \n",
      "244552 246496 248440 250384 252328 254272 256216 258160 260104 262048 263992 265936 267880 269824 271768 273712 \n",
      "276040 278240 280440 282640 284840 287040 289240 291440 293640 295840 298040 300240 302440 304640 306840 309040 \n",
      "307528 309984 312440 314896 317352 319808 322264 324720 327176 329632 332088 334544 337000 339456 341912 344368 \n",
      "339016 341728 344440 347152 349864 352576 355288 358000 360712 363424 366136 368848 371560 374272 376984 379696 \n",
      "370504 373472 376440 379408 382376 385344 388312 391280 394248 397216 400184 403152 406120 409088 412056 415024 \n",
      "401992 405216 408440 411664 414888 418112 421336 424560 427784 431008 434232 437456 440680 443904 447128 450352 \n",
      "433480 436960 440440 443920 447400 450880 454360 457840 461320 464800 468280 471760 475240 478720 482200 485680 \n",
      "464968 468704 472440 476176 479912 483648 487384 491120 494856 498592 502328 506064 509800 513536 517272 521008 \n",
      "496456 500448 504440 508432 512424 516416 520408 524400 528392 532384 536376 540368 544360 548352 552344 556336 \n",
      "PASS\n",
      "\n",
      "########################################################################\n",
      "# End of output for job 2256261.v-qsvr-1.aidevcloud\n",
      "# Date: Sat 18 Mar 2023 05:07:13 PM PDT\n",
      "########################################################################\n",
      "\n",
      "icpx: warning: use of 'dpcpp' is deprecated and will be removed in a future release. Use 'icpx -fsycl' [-Wdeprecated]\n",
      "lab/matrixmul_16x16_localmem.cpp:56:70: warning: 'local' is deprecated: use `local_accessor` instead [-Wdeprecated-declarations]\n",
      "        accessor<float, 2, access::mode::read_write, access::target::local> A_local(range<2>(N, N), h);\n",
      "                                                                     ^\n",
      "/glob/development-tools/versions/oneapi/2023.0.1/oneapi/compiler/2023.0.0/linux/bin-llvm/../include/sycl/access/access.hpp:20:9: note: 'local' has been explicitly marked deprecated here\n",
      "  local __SYCL2020_DEPRECATED(\"use `local_accessor` instead\") = 2016,\n",
      "        ^\n",
      "/glob/development-tools/versions/oneapi/2023.0.1/oneapi/compiler/2023.0.0/linux/bin-llvm/../include/sycl/detail/defines_elementary.hpp:52:40: note: expanded from macro '__SYCL2020_DEPRECATED'\n",
      "#define __SYCL2020_DEPRECATED(message) __SYCL_DEPRECATED(message)\n",
      "                                       ^\n",
      "/glob/development-tools/versions/oneapi/2023.0.1/oneapi/compiler/2023.0.0/linux/bin-llvm/../include/sycl/detail/defines_elementary.hpp:43:38: note: expanded from macro '__SYCL_DEPRECATED'\n",
      "#define __SYCL_DEPRECATED(message) [[deprecated(message)]]\n",
      "                                     ^\n",
      "lab/matrixmul_16x16_localmem.cpp:57:70: warning: 'local' is deprecated: use `local_accessor` instead [-Wdeprecated-declarations]\n",
      "        accessor<float, 2, access::mode::read_write, access::target::local> B_local(range<2>(N, N), h);\n",
      "                                                                     ^\n",
      "/glob/development-tools/versions/oneapi/2023.0.1/oneapi/compiler/2023.0.0/linux/bin-llvm/../include/sycl/access/access.hpp:20:9: note: 'local' has been explicitly marked deprecated here\n",
      "  local __SYCL2020_DEPRECATED(\"use `local_accessor` instead\") = 2016,\n",
      "        ^\n",
      "/glob/development-tools/versions/oneapi/2023.0.1/oneapi/compiler/2023.0.0/linux/bin-llvm/../include/sycl/detail/defines_elementary.hpp:52:40: note: expanded from macro '__SYCL2020_DEPRECATED'\n",
      "#define __SYCL2020_DEPRECATED(message) __SYCL_DEPRECATED(message)\n",
      "                                       ^\n",
      "/glob/development-tools/versions/oneapi/2023.0.1/oneapi/compiler/2023.0.0/linux/bin-llvm/../include/sycl/detail/defines_elementary.hpp:43:38: note: expanded from macro '__SYCL_DEPRECATED'\n",
      "#define __SYCL_DEPRECATED(message) [[deprecated(message)]]\n",
      "                                     ^\n",
      "2 warnings generated.\n",
      "lab/matrixmul_16x16_localmem.cpp:56:70: warning: 'local' is deprecated: use `local_accessor` instead [-Wdeprecated-declarations]\n",
      "        accessor<float, 2, access::mode::read_write, access::target::local> A_local(range<2>(N, N), h);\n",
      "                                                                     ^\n",
      "/glob/development-tools/versions/oneapi/2023.0.1/oneapi/compiler/2023.0.0/linux/bin-llvm/../include/sycl/access/access.hpp:20:9: note: 'local' has been explicitly marked deprecated here\n",
      "  local __SYCL2020_DEPRECATED(\"use `local_accessor` instead\") = 2016,\n",
      "        ^\n",
      "/glob/development-tools/versions/oneapi/2023.0.1/oneapi/compiler/2023.0.0/linux/bin-llvm/../include/sycl/detail/defines_elementary.hpp:52:40: note: expanded from macro '__SYCL2020_DEPRECATED'\n",
      "#define __SYCL2020_DEPRECATED(message) __SYCL_DEPRECATED(message)\n",
      "                                       ^\n",
      "/glob/development-tools/versions/oneapi/2023.0.1/oneapi/compiler/2023.0.0/linux/bin-llvm/../include/sycl/detail/defines_elementary.hpp:43:38: note: expanded from macro '__SYCL_DEPRECATED'\n",
      "#define __SYCL_DEPRECATED(message) [[deprecated(message)]]\n",
      "                                     ^\n",
      "lab/matrixmul_16x16_localmem.cpp:57:70: warning: 'local' is deprecated: use `local_accessor` instead [-Wdeprecated-declarations]\n",
      "        accessor<float, 2, access::mode::read_write, access::target::local> B_local(range<2>(N, N), h);\n",
      "                                                                     ^\n",
      "/glob/development-tools/versions/oneapi/2023.0.1/oneapi/compiler/2023.0.0/linux/bin-llvm/../include/sycl/access/access.hpp:20:9: note: 'local' has been explicitly marked deprecated here\n",
      "  local __SYCL2020_DEPRECATED(\"use `local_accessor` instead\") = 2016,\n",
      "        ^\n",
      "/glob/development-tools/versions/oneapi/2023.0.1/oneapi/compiler/2023.0.0/linux/bin-llvm/../include/sycl/detail/defines_elementary.hpp:52:40: note: expanded from macro '__SYCL2020_DEPRECATED'\n",
      "#define __SYCL2020_DEPRECATED(message) __SYCL_DEPRECATED(message)\n",
      "                                       ^\n",
      "/glob/development-tools/versions/oneapi/2023.0.1/oneapi/compiler/2023.0.0/linux/bin-llvm/../include/sycl/detail/defines_elementary.hpp:43:38: note: expanded from macro '__SYCL_DEPRECATED'\n",
      "#define __SYCL_DEPRECATED(message) [[deprecated(message)]]\n",
      "                                     ^\n",
      "2 warnings generated.\n",
      "Job Completed in 30 seconds.\n"
     ]
    }
   ],
   "source": [
    "! chmod 755 q; chmod 755 run_matrixmul_16x16.sh; if [ -x \"$(command -v qsub)\" ]; then ./q run_matrixmul_16x16.sh; else ./run_matrixmul_16x16.sh; fi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3789b4-e3fc-4cd4-8ac2-77b8c7dbae05",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Matrix Multiplication with Local Memory\n",
    "\n",
    "The code below demonstrates matrix multiplication example making use of local memory. Inspect code, there are no modifications necessary:\n",
    "\n",
    "1. Inspect the code cell below and click run ▶ to save the code to file.\n",
    "\n",
    "2. Next run ▶ the cell in the __Build and Run__ section below the code to compile and execute the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48f5d945-4932-465f-b3db-f9d5280d8a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting lab/matrixmul_16x16_localmem.cpp\n"
     ]
    }
   ],
   "source": [
    "%%writefile lab/matrixmul_16x16_localmem.cpp\n",
    "//==============================================================\n",
    "// Copyright © Intel Corporation\n",
    "//\n",
    "// SPDX-License-Identifier: MIT\n",
    "// =============================================================\n",
    "\n",
    "\n",
    "#include <CL/sycl.hpp>\n",
    "#include <iomanip>\n",
    "\n",
    "using namespace sycl;\n",
    "\n",
    "int main() {\n",
    "    \n",
    "    size_t N = 16;\n",
    "    std::cout << \"MATRIX_SIZE    : \" << N << \"x\" << N << std::endl;\n",
    "\n",
    "    //# Define vectors for matrices\n",
    "    std::vector<float> matrix_a(N*N);\n",
    "    std::vector<float> matrix_b(N*N);\n",
    "    std::vector<float> matrix_c(N*N);\n",
    "    std::vector<float> matrix_d(N*N);\n",
    "    \n",
    "    //# Initialize matrices with values\n",
    "    float v1 = 2.f;\n",
    "    float v2 = 3.f;\n",
    "    for (int i=0; i<N; i++)\n",
    "        for (int j=0; j<N; j++){\n",
    "            matrix_a[i*N+j] = v1++;\n",
    "            matrix_b[i*N+j] = v2++;\n",
    "            matrix_c[i*N+j] = 0.f;\n",
    "            matrix_d[i*N+j] = 0.f;\n",
    "    }\n",
    "    \n",
    "    //# Define queue with default device for offloading computation\n",
    "    queue q;\n",
    "    std::cout << \"Offload Device : \" << q.get_device().get_info<info::device::name>() << std::endl;\n",
    "    \n",
    "    //# Create buffers for matrices\n",
    "    buffer a(matrix_a);\n",
    "    buffer b(matrix_b);\n",
    "    buffer c(matrix_c);\n",
    "\n",
    "    //# Submit command groups to execute on device\n",
    "    q.submit([&](handler &h){\n",
    "        //# Create accessors to copy buffers to the device\n",
    "        accessor A(a, h, read_only);\n",
    "        accessor B(b, h, read_only);\n",
    "        accessor C(c, h, write_only);\n",
    "\n",
    "        //# Define size for ND-range and work-group size\n",
    "        range<2> global_size(N,N);\n",
    "        range<2> work_group_size(N,N);\n",
    "\n",
    "        //# Create local accessors\n",
    "        accessor<float, 2, access::mode::read_write, access::target::local> A_local(range<2>(N, N), h);\n",
    "        accessor<float, 2, access::mode::read_write, access::target::local> B_local(range<2>(N, N), h);\n",
    "\n",
    "        //# Parallel Compute Matrix Multiplication\n",
    "        h.parallel_for(nd_range<2>{global_size, work_group_size}, [=](nd_item<2> item){\n",
    "            const int i = item.get_global_id(0);\n",
    "            const int j = item.get_global_id(1);\n",
    "            const int x = item.get_local_id(0);\n",
    "            const int y = item.get_local_id(1);\n",
    "\n",
    "            //# copy from global to local memory\n",
    "            A_local[x][y] = A[i * N + j];\n",
    "            B_local[x][y] = B[i * N + j];\n",
    "\n",
    "            //# barrier to sychronize local memory copy across all work items\n",
    "            group_barrier(item.get_group());\n",
    "\n",
    "            //# matrix multiplication computation from local memory\n",
    "            float temp = 0.f;\n",
    "            for (int k = 0; k < N; k++) {\n",
    "                temp += A_local[x][k] * B_local[k][y];\n",
    "            }\n",
    "            C[i*N+j] = temp;\n",
    "        });\n",
    "    });\n",
    "    host_accessor ha(c, read_only);\n",
    "    \n",
    "    //# Print Output and Verification\n",
    "    auto FAIL = 0;\n",
    "    for (int i=0; i<N; i++){\n",
    "        for (int j=0; j<N; j++){\n",
    "            for(int k=0; k<N; k++){\n",
    "                matrix_d[i*N+j] += matrix_a[i*N+k] * matrix_b[k*N+j];\n",
    "            }\n",
    "            if(matrix_d[i*N+j] != matrix_c[i*N+j]) FAIL = 1;\n",
    "            std::cout << std::setw(6) << matrix_c[i*N+j] << \" \";\n",
    "        }\n",
    "        std::cout << \"\\n\";\n",
    "    }\n",
    "    if(FAIL == 1) std::cout << \"FAIL\\n\"; else std::cout << \"PASS\\n\";\n",
    "\n",
    "    return 0;\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78d4525-bd6a-483e-80fc-d5414ea6beef",
   "metadata": {},
   "source": [
    "#### Build and Run\n",
    "Select the cell below and click run ▶ to compile and execute the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55fb4c03-3538-4571-9522-71433ed41015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job has been submitted to Intel(R) DevCloud and will execute soon.\n",
      "\n",
      "Job ID                    Name             User            Time Use S Queue\n",
      "------------------------- ---------------- --------------- -------- - -----\n",
      "2256147.v-qsvr-1           ...ub-singleuser u181188         00:01:00 R jupyterhub     \n",
      "2256226.v-qsvr-1           run_simple.sh    u181188         00:15:41 R batch          \n",
      "2256264.v-qsvr-1           ...sm_pointer.sh u181188                0 R batch          \n",
      "2256265.v-qsvr-1           ...ary_search.sh u181188                0 R batch          \n",
      "2256266.v-qsvr-1           ...on_buffers.sh u181188                0 R batch          \n",
      "2256267.v-qsvr-1           ...6_localmem.sh u181188                0 Q batch          \n",
      "\n",
      "Waiting for Output █████████████████████████████████████████ Done⬇\n",
      "\n",
      "########################################################################\n",
      "#      Date:           Sat 18 Mar 2023 05:07:33 PM PDT\n",
      "#    Job ID:           2256267.v-qsvr-1.aidevcloud\n",
      "#      User:           u181188\n",
      "# Resources:           cput=75:00:00,neednodes=1:gpu:ppn=2,nodes=1:gpu:ppn=2,walltime=06:00:00\n",
      "########################################################################\n",
      "\n",
      "## u181188 is compiling DPCPP_Essentials Module12 -- DPCPP Atomics Local Memory - 5 of 5 matrixmul_16x16_localmem.cpp\n",
      "MATRIX_SIZE    : 16x16\n",
      "Offload Device : Intel(R) UHD Graphics [0x9a60]\n",
      " 24136  24288  24440  24592  24744  24896  25048  25200  25352  25504  25656  25808  25960  26112  26264  26416 \n",
      " 55624  56032  56440  56848  57256  57664  58072  58480  58888  59296  59704  60112  60520  60928  61336  61744 \n",
      " 87112  87776  88440  89104  89768  90432  91096  91760  92424  93088  93752  94416  95080  95744  96408  97072 \n",
      "118600 119520 120440 121360 122280 123200 124120 125040 125960 126880 127800 128720 129640 130560 131480 132400 \n",
      "150088 151264 152440 153616 154792 155968 157144 158320 159496 160672 161848 163024 164200 165376 166552 167728 \n",
      "181576 183008 184440 185872 187304 188736 190168 191600 193032 194464 195896 197328 198760 200192 201624 203056 \n",
      "213064 214752 216440 218128 219816 221504 223192 224880 226568 228256 229944 231632 233320 235008 236696 238384 \n",
      "244552 246496 248440 250384 252328 254272 256216 258160 260104 262048 263992 265936 267880 269824 271768 273712 \n",
      "276040 278240 280440 282640 284840 287040 289240 291440 293640 295840 298040 300240 302440 304640 306840 309040 \n",
      "307528 309984 312440 314896 317352 319808 322264 324720 327176 329632 332088 334544 337000 339456 341912 344368 \n",
      "339016 341728 344440 347152 349864 352576 355288 358000 360712 363424 366136 368848 371560 374272 376984 379696 \n",
      "370504 373472 376440 379408 382376 385344 388312 391280 394248 397216 400184 403152 406120 409088 412056 415024 \n",
      "401992 405216 408440 411664 414888 418112 421336 424560 427784 431008 434232 437456 440680 443904 447128 450352 \n",
      "433480 436960 440440 443920 447400 450880 454360 457840 461320 464800 468280 471760 475240 478720 482200 485680 \n",
      "464968 468704 472440 476176 479912 483648 487384 491120 494856 498592 502328 506064 509800 513536 517272 521008 \n",
      "496456 500448 504440 508432 512424 516416 520408 524400 528392 532384 536376 540368 544360 548352 552344 556336 \n",
      "PASS\n",
      "\n",
      "########################################################################\n",
      "# End of output for job 2256267.v-qsvr-1.aidevcloud\n",
      "# Date: Sat 18 Mar 2023 05:07:43 PM PDT\n",
      "########################################################################\n",
      "\n",
      "icpx: warning: use of 'dpcpp' is deprecated and will be removed in a future release. Use 'icpx -fsycl' [-Wdeprecated]\n",
      "lab/matrixmul_16x16_localmem.cpp:56:70: warning: 'local' is deprecated: use `local_accessor` instead [-Wdeprecated-declarations]\n",
      "        accessor<float, 2, access::mode::read_write, access::target::local> A_local(range<2>(N, N), h);\n",
      "                                                                     ^\n",
      "/glob/development-tools/versions/oneapi/2023.0.1/oneapi/compiler/2023.0.0/linux/bin-llvm/../include/sycl/access/access.hpp:20:9: note: 'local' has been explicitly marked deprecated here\n",
      "  local __SYCL2020_DEPRECATED(\"use `local_accessor` instead\") = 2016,\n",
      "        ^\n",
      "/glob/development-tools/versions/oneapi/2023.0.1/oneapi/compiler/2023.0.0/linux/bin-llvm/../include/sycl/detail/defines_elementary.hpp:52:40: note: expanded from macro '__SYCL2020_DEPRECATED'\n",
      "#define __SYCL2020_DEPRECATED(message) __SYCL_DEPRECATED(message)\n",
      "                                       ^\n",
      "/glob/development-tools/versions/oneapi/2023.0.1/oneapi/compiler/2023.0.0/linux/bin-llvm/../include/sycl/detail/defines_elementary.hpp:43:38: note: expanded from macro '__SYCL_DEPRECATED'\n",
      "#define __SYCL_DEPRECATED(message) [[deprecated(message)]]\n",
      "                                     ^\n",
      "lab/matrixmul_16x16_localmem.cpp:57:70: warning: 'local' is deprecated: use `local_accessor` instead [-Wdeprecated-declarations]\n",
      "        accessor<float, 2, access::mode::read_write, access::target::local> B_local(range<2>(N, N), h);\n",
      "                                                                     ^\n",
      "/glob/development-tools/versions/oneapi/2023.0.1/oneapi/compiler/2023.0.0/linux/bin-llvm/../include/sycl/access/access.hpp:20:9: note: 'local' has been explicitly marked deprecated here\n",
      "  local __SYCL2020_DEPRECATED(\"use `local_accessor` instead\") = 2016,\n",
      "        ^\n",
      "/glob/development-tools/versions/oneapi/2023.0.1/oneapi/compiler/2023.0.0/linux/bin-llvm/../include/sycl/detail/defines_elementary.hpp:52:40: note: expanded from macro '__SYCL2020_DEPRECATED'\n",
      "#define __SYCL2020_DEPRECATED(message) __SYCL_DEPRECATED(message)\n",
      "                                       ^\n",
      "/glob/development-tools/versions/oneapi/2023.0.1/oneapi/compiler/2023.0.0/linux/bin-llvm/../include/sycl/detail/defines_elementary.hpp:43:38: note: expanded from macro '__SYCL_DEPRECATED'\n",
      "#define __SYCL_DEPRECATED(message) [[deprecated(message)]]\n",
      "                                     ^\n",
      "2 warnings generated.\n",
      "lab/matrixmul_16x16_localmem.cpp:56:70: warning: 'local' is deprecated: use `local_accessor` instead [-Wdeprecated-declarations]\n",
      "        accessor<float, 2, access::mode::read_write, access::target::local> A_local(range<2>(N, N), h);\n",
      "                                                                     ^\n",
      "/glob/development-tools/versions/oneapi/2023.0.1/oneapi/compiler/2023.0.0/linux/bin-llvm/../include/sycl/access/access.hpp:20:9: note: 'local' has been explicitly marked deprecated here\n",
      "  local __SYCL2020_DEPRECATED(\"use `local_accessor` instead\") = 2016,\n",
      "        ^\n",
      "/glob/development-tools/versions/oneapi/2023.0.1/oneapi/compiler/2023.0.0/linux/bin-llvm/../include/sycl/detail/defines_elementary.hpp:52:40: note: expanded from macro '__SYCL2020_DEPRECATED'\n",
      "#define __SYCL2020_DEPRECATED(message) __SYCL_DEPRECATED(message)\n",
      "                                       ^\n",
      "/glob/development-tools/versions/oneapi/2023.0.1/oneapi/compiler/2023.0.0/linux/bin-llvm/../include/sycl/detail/defines_elementary.hpp:43:38: note: expanded from macro '__SYCL_DEPRECATED'\n",
      "#define __SYCL_DEPRECATED(message) [[deprecated(message)]]\n",
      "                                     ^\n",
      "lab/matrixmul_16x16_localmem.cpp:57:70: warning: 'local' is deprecated: use `local_accessor` instead [-Wdeprecated-declarations]\n",
      "        accessor<float, 2, access::mode::read_write, access::target::local> B_local(range<2>(N, N), h);\n",
      "                                                                     ^\n",
      "/glob/development-tools/versions/oneapi/2023.0.1/oneapi/compiler/2023.0.0/linux/bin-llvm/../include/sycl/access/access.hpp:20:9: note: 'local' has been explicitly marked deprecated here\n",
      "  local __SYCL2020_DEPRECATED(\"use `local_accessor` instead\") = 2016,\n",
      "        ^\n",
      "/glob/development-tools/versions/oneapi/2023.0.1/oneapi/compiler/2023.0.0/linux/bin-llvm/../include/sycl/detail/defines_elementary.hpp:52:40: note: expanded from macro '__SYCL2020_DEPRECATED'\n",
      "#define __SYCL2020_DEPRECATED(message) __SYCL_DEPRECATED(message)\n",
      "                                       ^\n",
      "/glob/development-tools/versions/oneapi/2023.0.1/oneapi/compiler/2023.0.0/linux/bin-llvm/../include/sycl/detail/defines_elementary.hpp:43:38: note: expanded from macro '__SYCL_DEPRECATED'\n",
      "#define __SYCL_DEPRECATED(message) [[deprecated(message)]]\n",
      "                                     ^\n",
      "2 warnings generated.\n",
      "Job Completed in 41 seconds.\n"
     ]
    }
   ],
   "source": [
    "! chmod 755 q; chmod 755 run_matrixmul_16x16_localmem.sh; if [ -x \"$(command -v qsub)\" ]; then ./q run_matrixmul_16x16_localmem.sh; else ./run_matrixmul_16x16_localmem.sh; fi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30865b8d-3304-4083-814c-0cbf5147e9e9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Atomic Operations\n",
    "\n",
    "Atomic operations enable __concurrent access to a memory location without introducing a data race__. When multiple atomic operations access the same memory, they are guaranteed not to overlap. \n",
    "\n",
    "To understand why atomic operations are necessary, let look at few kernel examples to perform reduction, addition of N number of elements:\n",
    "\n",
    "#### Serial Computation with single_task\n",
    "A simple way to perform reduction is by using a for-loop to add all items in a single_task kernel submission as show below, but it does not take advantage of parallelism in hardware.\n",
    "```cpp\n",
    "     q.single_task([=](){\n",
    "       for(int i=0; i<N; i++){\n",
    "         sum[0] += data[i];\n",
    "       }\n",
    "     });\n",
    "```\n",
    "\n",
    "#### Parallel Computation with parallel_for may encounter race conditions\n",
    "Using parallel_for for kernel submission will enable multiple work-items to execute concurrently but multiple work-item may try to update the same output variable causing __race conditions__.\n",
    "```cpp\n",
    "      q.parallel_for(N, [=](auto i) {\n",
    "        sum[0] += data[i];\n",
    "      });\n",
    "```\n",
    "\n",
    "\n",
    "#### Parallel Computation with atomic operation\n",
    "The code snippet below show how to avoid race conditions when multiple work-items are trying to update the same memory location using atomic operations\n",
    "```cpp\n",
    "      q.parallel_for(N, [=](auto i) {\n",
    "        auto atomic_var = atomic_ref<int, memory_order::relaxed, memory_scope::device, access::address_space::global_space>(sum[0]);\n",
    "\n",
    "        atomic_var.fetch_add(data[i]);\n",
    "      });\n",
    "```\n",
    "\n",
    "### atomic_ref class\n",
    "The `atomic_ref` class above will make sure that the referenced variable will only be accessed atomically for the lifetime of the reference. It also specifies the _data type_, _memory order_ and _memory scope_.\n",
    "\n",
    "```cpp\n",
    "  auto atomic_var = atomic_ref<int, memory_order::relaxed, memory_scope::device, access::address_space::global_space>(result[0]);\n",
    "```\n",
    "\n",
    "\n",
    "#### memory_order\n",
    "By providing the compiler with information about our desired memory order, we can prevent re-ordering optimizations that are incompatible with the intended behavior of our applications.\n",
    "- `memory_order::relaxed`: Read and write operations can be re-ordered before or after the operation with no restrictions. There are no ordering guarantees.\n",
    "- `memory_order::acquire`: Read and write operations appearing after the operation in the program must occur after it.\n",
    "- `memory_order::release`:\n",
    "Read and write operations appearing before the operation in the program must occur before it , and preceding write operations are guaranteed to be visible to other program instances which have been synchronized by a corresponding acquire operation.\n",
    "- `memory_order::acq_rel`: \n",
    "The operation acts as both an acquire and a release. Read and write operations cannot be re-ordered around the operation, and preceding writes must be made visible as previously described for _memory_order::release_.\n",
    "- `memory_order::seq_cst`: \n",
    "The operation acts as an acquire, release, or both depending on whether it is a read, write, or read-modify-write operation, respectively. All operations with this memory order are observed in a sequentially consistent order.\n",
    "\n",
    "#### memory_scope\n",
    "- `memory_scope::work_item`: The memory ordering constraint applies only to the calling work-item. This scope is only useful for image operations, as all other operations within a work-item are already guaranteed to execute in program order.\n",
    "- `memory_scope::work_group`: The memory ordering constraint applies only to work-items in the same work-group as the calling work-item.\n",
    "- `memory_scope::sub_group`: The memory ordering constraint applies only to work-items in the same sub-group as the calling work-item.\n",
    "- `memory_scope::device`: The memory ordering constraint applies only to work-items executing on the same device as the calling work-item.\n",
    "- `memory_scope::system`:  The memory ordering constraint applies to all work-items in the system.\n",
    "\n",
    "### atomic operations\n",
    "\n",
    "Atomic references to objects of integral and floating-point types extend the set of available atomic operations to include arithmetic operations\n",
    "\n",
    "```cpp\n",
    "        // integer and floating point\n",
    "        atomic_var += data[i];         // addition\n",
    "        atomic_var.fetch_add(data[i]); // addition\n",
    "        atomic_var -= data[i];         // subtraction\n",
    "        atomic_var.fetch_sub(data[i]); // subtraction\n",
    "        atomic_var.fetch_max(data[i]); // maximum\n",
    "        atomic_var.fetch_min(data[i]); // minimum\n",
    "        // integer only\n",
    "        atomic_var.fetch_and(data[i]); // bitwise AND\n",
    "        atomic_var.fetch_or(data[i]);  // bitwise OR\n",
    "        atomic_var.fetch_xor(data[i]); // bitwise XOR\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ed385f-9808-4012-987e-7343a35e8c2b",
   "metadata": {},
   "source": [
    "### Atomic Operations with Buffers\n",
    "\n",
    "The code below uses atomic operation to perform reduction with buffers memory model. Inspect code, there are no modifications necessary.\n",
    "\n",
    "_[Note that using atomics to do reduction operation is not best approach, but it a easy example to demonstrate atomic operation functionality, for better performance with reduction can be achieved using SYCL reduction kernels]_\n",
    "\n",
    "1. Inspect the code cell below and click run ▶ to save the code to file.\n",
    "\n",
    "2. Next run ▶ the cell in the __Build and Run__ section below the code to compile and execute the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "812e7e6a-ddd4-4fe2-9fb5-3b7c1e652d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting lab/reduction_atomics_buffer.cpp\n"
     ]
    }
   ],
   "source": [
    "%%writefile lab/reduction_atomics_buffer.cpp\n",
    "//==============================================================\n",
    "// Copyright © Intel Corporation\n",
    "//\n",
    "// SPDX-License-Identifier: MIT\n",
    "// =============================================================\n",
    "#include <CL/sycl.hpp>\n",
    "\n",
    "using namespace sycl;\n",
    "\n",
    "static constexpr size_t N = 1024; // global size\n",
    "\n",
    "int main() {\n",
    "  queue q;\n",
    "  std::cout << \"Device : \" << q.get_device().get_info<info::device::name>() << \"\\n\";\n",
    "\n",
    "  std::vector<int> data(N);\n",
    "  for (int i = 0; i < N; i++) data[i] = i;\n",
    "  int sum = 0;\n",
    "  {\n",
    "    //# create buffers for data and sum\n",
    "    buffer buf_data(data);\n",
    "    buffer buf_sum(&sum, range(1));\n",
    "\n",
    "    //# Reduction Kernel using atomics \n",
    "    q.submit([&](auto &h) {\n",
    "      accessor data_acc(buf_data, h, sycl::read_only);\n",
    "      accessor sum_acc(buf_sum, h);\n",
    "\n",
    "      h.parallel_for(N, [=](auto i) {\n",
    "        auto sum_atomic = atomic_ref<int, \n",
    "          memory_order::relaxed, \n",
    "          memory_scope::device, \n",
    "          access::address_space::global_space>(sum_acc[0]);\n",
    "        sum_atomic += data_acc[i];\n",
    "      });\n",
    "    });\n",
    "  }\n",
    "  std::cout << \"Sum = \" << sum << \"\\n\";\n",
    "\n",
    "  return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd05768-3154-4479-a58d-1075f58f0083",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Build and Run\n",
    "Select the cell below and click run ▶ to compile and execute the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5731ed45-6743-4ec1-bd7b-128477fa542e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job has been submitted to Intel(R) DevCloud and will execute soon.\n",
      "\n",
      "Job ID                    Name             User            Time Use S Queue\n",
      "------------------------- ---------------- --------------- -------- - -----\n",
      "2256147.v-qsvr-1           ...ub-singleuser u181188         00:01:10 R jupyterhub     \n",
      "2256226.v-qsvr-1           run_simple.sh    u181188         00:16:26 R batch          \n",
      "2256275.v-qsvr-1           ..._broadcast.sh u181188                0 R batch          \n",
      "2256276.v-qsvr-1           ...t_accessor.sh u181188                0 Q batch          \n",
      "2256277.v-qsvr-1           ...ics_buffer.sh u181188                0 Q batch          \n",
      "\n",
      "Waiting for Output ██████████████████████████████ Done⬇\n",
      "\n",
      "########################################################################\n",
      "#      Date:           Sat 18 Mar 2023 05:08:14 PM PDT\n",
      "#    Job ID:           2256277.v-qsvr-1.aidevcloud\n",
      "#      User:           u181188\n",
      "# Resources:           cput=75:00:00,neednodes=1:gpu:ppn=2,nodes=1:gpu:ppn=2,walltime=06:00:00\n",
      "########################################################################\n",
      "\n",
      "## u181188 is compiling DPCPP_Essentials Module12 -- DPCPP Atomics Local Memory - 1 of 5 reduction_atomics_buffer.cpp\n",
      "Device : Intel(R) UHD Graphics [0x9a60]\n",
      "Sum = 523776\n",
      "\n",
      "########################################################################\n",
      "# End of output for job 2256277.v-qsvr-1.aidevcloud\n",
      "# Date: Sat 18 Mar 2023 05:08:23 PM PDT\n",
      "########################################################################\n",
      "\n",
      "icpx: warning: use of 'dpcpp' is deprecated and will be removed in a future release. Use 'icpx -fsycl' [-Wdeprecated]\n",
      "Job Completed in 30 seconds.\n"
     ]
    }
   ],
   "source": [
    "! chmod 755 q; chmod 755 run_reduction_atomics_buffer.sh; if [ -x \"$(command -v qsub)\" ]; then ./q run_reduction_atomics_buffer.sh; else ./run_reduction_atomics_buffer.sh; fi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1775bb0-7e49-4da2-8777-548da487bc1b",
   "metadata": {},
   "source": [
    "### Atomic Operations with USM\n",
    "\n",
    "The code below uses atomic operation to perform reduction with Unified Shared memory. Inspect code, there are no modifications necessary.\n",
    "\n",
    "_[Note that using atomics to do reduction operation is not best approach, but it a easy example to demonstrate atomic operation functionality, for better performance with reduction can be achieved using SYCL reduction kernels]_\n",
    "\n",
    "1. Inspect the code cell below and click run ▶ to save the code to file.\n",
    "\n",
    "2. Next run ▶ the cell in the __Build and Run__ section below the code to compile and execute the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0639250-e30c-4744-b360-08fb04ee116d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting lab/reduction_atomics_usm.cpp\n"
     ]
    }
   ],
   "source": [
    "%%writefile lab/reduction_atomics_usm.cpp\n",
    "//==============================================================\n",
    "// Copyright © Intel Corporation\n",
    "//\n",
    "// SPDX-License-Identifier: MIT\n",
    "// =============================================================\n",
    "#include <CL/sycl.hpp>\n",
    "\n",
    "using namespace sycl;\n",
    "\n",
    "static constexpr size_t N = 1024; // global size\n",
    "\n",
    "int main() {\n",
    "  queue q;\n",
    "  std::cout << \"Device : \" << q.get_device().get_info<info::device::name>() << \"\\n\";\n",
    "\n",
    "  auto data = malloc_shared<int>(N, q);\n",
    "  for (int i = 0; i < N; i++) data[i] = i;\n",
    "  auto sum = malloc_shared<int>(1, q);\n",
    "  sum[0] = 0;\n",
    "\n",
    "  //# Reduction Kernel using atomics \n",
    "  q.parallel_for(N, [=](auto i) {\n",
    "    auto sum_atomic = atomic_ref<int, \n",
    "      memory_order::relaxed, \n",
    "      memory_scope::device, \n",
    "      access::address_space::global_space>(sum[0]);\n",
    "    sum_atomic += data[i];\n",
    "  }).wait();\n",
    "\n",
    "  std::cout << \"Sum = \" << sum[0] << \"\\n\";\n",
    "  return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba49aab-bb7c-46ff-9f66-9c1b2e179988",
   "metadata": {},
   "source": [
    "#### Build and Run\n",
    "Select the cell below and click run ▶ to compile and execute the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79b991f0-bd9f-487e-aabe-6e001e43263a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job has been submitted to Intel(R) DevCloud and will execute soon.\n",
      "\n",
      "Job ID                    Name             User            Time Use S Queue\n",
      "------------------------- ---------------- --------------- -------- - -----\n",
      "2256147.v-qsvr-1           ...ub-singleuser u181188         00:01:10 R jupyterhub     \n",
      "2256226.v-qsvr-1           run_simple.sh    u181188         00:17:11 R batch          \n",
      "2256282.v-qsvr-1           ...essor_init.sh u181188                0 Q batch          \n",
      "2256283.v-qsvr-1           ...tomics_usm.sh u181188                0 Q batch          \n",
      "\n",
      "Waiting for Output ██████████████████████████████ Done⬇\n",
      "\n",
      "########################################################################\n",
      "#      Date:           Sat 18 Mar 2023 05:08:45 PM PDT\n",
      "#    Job ID:           2256283.v-qsvr-1.aidevcloud\n",
      "#      User:           u181188\n",
      "# Resources:           cput=75:00:00,neednodes=1:gpu:ppn=2,nodes=1:gpu:ppn=2,walltime=06:00:00\n",
      "########################################################################\n",
      "\n",
      "## u181188 is compiling DPCPP_Essentials Module12 -- DPCPP Atomics Local Memory - 1 of 5 reduction_atomics_usm.cpp\n",
      "Device : Intel(R) UHD Graphics [0x9a60]\n",
      "Sum = 523776\n",
      "\n",
      "########################################################################\n",
      "# End of output for job 2256283.v-qsvr-1.aidevcloud\n",
      "# Date: Sat 18 Mar 2023 05:08:55 PM PDT\n",
      "########################################################################\n",
      "\n",
      "icpx: warning: use of 'dpcpp' is deprecated and will be removed in a future release. Use 'icpx -fsycl' [-Wdeprecated]\n",
      "Job Completed in 30 seconds.\n"
     ]
    }
   ],
   "source": [
    "! chmod 755 q; chmod 755 run_reduction_atomics_usm.sh; if [ -x \"$(command -v qsub)\" ]; then ./q run_reduction_atomics_usm.sh; else ./run_reduction_atomics_usm.sh; fi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9224377-ff8c-45fc-afdd-17c0ae8bf9d0",
   "metadata": {},
   "source": [
    "## Lab Exercise: Atomic Operations\n",
    "\n",
    "Complete the coding exercise below using Atomic Operations:\n",
    "- The code has an array `data` of size `N=1024` elements initialized\n",
    "- We will offload kernel task to find the minimum and maximum values from the `data` array using atomic operations\n",
    "- Create atomic reference for minimum and maximum variables\n",
    "- Create atomic operation in kernel to find minimum and maximum\n",
    "- On the host, compute mid-range, which is average of min and max values\n",
    "\n",
    "1. Edit the code cell below by following the steps and then click run ▶ to save the code to a file.\n",
    "2. Next run ▶ the cell in the __Build and Run__ section below the code to compile and execute the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2af66e69-45bf-442f-88c7-1478b6365631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting lab/atomics_lab.cpp\n"
     ]
    }
   ],
   "source": [
    "%%writefile lab/atomics_lab.cpp\n",
    "//==============================================================\n",
    "// Copyright © Intel Corporation\n",
    "//\n",
    "// SPDX-License-Identifier: MIT\n",
    "// =============================================================\n",
    "#include <CL/sycl.hpp>\n",
    "\n",
    "using namespace sycl;\n",
    "\n",
    "static constexpr size_t N = 1024; // global size\n",
    "\n",
    "int main() {\n",
    "  queue q;\n",
    "  std::cout << \"Device : \" << q.get_device().get_info<info::device::name>() << \"\\n\";\n",
    "\n",
    "  auto data = malloc_shared<int>(N, q);\n",
    "  for (int i = 0; i < N; i++) data[i] = i;\n",
    "  auto min = malloc_shared<int>(1, q);\n",
    "  auto max = malloc_shared<int>(1, q);\n",
    "  min[0] = 0;\n",
    "  max[0] = 0;\n",
    "\n",
    "  //# Reduction Kernel using atomics \n",
    "  q.parallel_for(N, [=](auto i) {\n",
    "    //# STEP 1: create atomic reference for min and max\n",
    "\n",
    "    //# YOUR CODE GOES HERE\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    //# STEP 2: add atomic operation for min and max computation  \n",
    "\n",
    "    //# YOUR CODE GOES HERE\n",
    "    \n",
    "    \n",
    "    \n",
    "  }).wait();\n",
    "\n",
    "  auto mid = 0.0;\n",
    "  //# STEP 3: Compute mid-range using the min and max \n",
    "\n",
    "  //# YOUR CODE GOES HERE\n",
    "    \n",
    "    \n",
    "    \n",
    "  \n",
    "  std::cout << \"Minimum   = \" << min[0] << \"\\n\";\n",
    "  std::cout << \"Maximum   = \" << max[0] << \"\\n\";\n",
    "  std::cout << \"Mid-Range = \" << mid << \"\\n\";\n",
    "\n",
    "  return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4dd8c8-3eca-4faf-a271-e27b708a242a",
   "metadata": {},
   "source": [
    "#### Build and Run\n",
    "Select the cell below and click run ▶ to compile and execute the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "008f9117-3ae5-4a6d-845e-c029f7acce23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job has been submitted to Intel(R) DevCloud and will execute soon.\n",
      "\n",
      "Job ID                    Name             User            Time Use S Queue\n",
      "------------------------- ---------------- --------------- -------- - -----\n",
      "2256147.v-qsvr-1           ...ub-singleuser u181188         00:01:24 R jupyterhub     \n",
      "2256226.v-qsvr-1           run_simple.sh    u181188         00:17:56 R batch          \n",
      "2256287.v-qsvr-1           ...sub_buffer.sh u181188                0 Q batch          \n",
      "2256288.v-qsvr-1           ...tomics_lab.sh u181188                0 Q batch          \n",
      "\n",
      "Waiting for Output █████████████████████████████ Done⬇\n",
      "\n",
      "########################################################################\n",
      "#      Date:           Sat 18 Mar 2023 05:09:16 PM PDT\n",
      "#    Job ID:           2256288.v-qsvr-1.aidevcloud\n",
      "#      User:           u181188\n",
      "# Resources:           cput=75:00:00,neednodes=1:gpu:ppn=2,nodes=1:gpu:ppn=2,walltime=06:00:00\n",
      "########################################################################\n",
      "\n",
      "## u181188 is compiling DPCPP_Essentials Module12 -- DPCPP Atomics Local Memory - 6 of 6 atomics_lab.cpp\n",
      "Device : Intel(R) UHD Graphics [0x9a60]\n",
      "Minimum   = 0\n",
      "Maximum   = 0\n",
      "Mid-Range = 0\n",
      "\n",
      "########################################################################\n",
      "# End of output for job 2256288.v-qsvr-1.aidevcloud\n",
      "# Date: Sat 18 Mar 2023 05:09:26 PM PDT\n",
      "########################################################################\n",
      "\n",
      "icpx: warning: use of 'dpcpp' is deprecated and will be removed in a future release. Use 'icpx -fsycl' [-Wdeprecated]\n",
      "Job Completed in 29 seconds.\n"
     ]
    }
   ],
   "source": [
    "! chmod 755 q; chmod 755 run_atomics_lab.sh; if [ -x \"$(command -v qsub)\" ]; then ./q run_atomics_lab.sh; else ./run_atomics_lab.sh; fi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a0bb06-3795-4ff8-81b1-9ede6bd6c510",
   "metadata": {
    "tags": []
   },
   "source": [
    "***\n",
    "# Summary\n",
    "\n",
    "In this module you learned:\n",
    "* How to setup and use Shared Local Memory in the device\n",
    "* How to use atomic operation when using buffers or USM\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Intel® oneAPI 2023.0)",
   "language": "python",
   "name": "c009-intel_distribution_of_python_3_oneapi-beta05-python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
